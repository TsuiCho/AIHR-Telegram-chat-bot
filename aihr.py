import os
import hashlib
import logging
import asyncio
import io
import json
import re
from typing import List, Dict, Optional
from pathlib import Path

import pdfplumber
from docx import Document
import asyncpg
from aiogram import Bot, Dispatcher, F, types
from aiogram.filters import Command
from aiogram.types import Message
from aiogram.enums import ParseMode
import httpx

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
DEEPSEEK_URL = "https://api.deepseek.com/v1/chat/completions"  # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ
DB_URL = os.getenv("SUPABASE_DB_URL")
MAX_FILE_SIZE = 5 * 1024 * 1024  # 5 MB
MAX_RESUMES = 50

bot = Bot(token=BOT_TOKEN)
dp = Dispatcher()

# –í—Ä–µ–º–µ–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π (–≤ –ø–∞–º—è—Ç–∏)
user_state = {}

# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î
async def get_db_conn():
    """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î"""
    try:
        conn = await asyncpg.connect(DB_URL)
        logging.info("–£—Å–ø–µ—à–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î")
        return conn
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î: {e}")
        raise

# –õ–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤
async def parse_resume(file_path: str) -> Optional[str]:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF/DOCX."""
    try:
        logging.info(f"–ü–æ–ø—ã—Ç–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ñ–∞–π–ª–∞: {file_path}")
        if not os.path.exists(file_path):
            logging.error(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∞ –¥–∏—Å–∫–µ: {file_path}")
            return None

        if file_path.endswith('.pdf'):
            with pdfplumber.open(file_path) as pdf:
                pages_text = []
                for i, page in enumerate(pdf.pages):
                    text = page.extract_text()
                    if text:
                        pages_text.append(text)
                    else:
                        logging.warning(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {i+1} –≤ PDF '{file_path}' –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞")
                return "\n".join(pages_text)
        elif file_path.endswith('.docx'):
            doc = Document(file_path)
            full_text = []
            for i, para in enumerate(doc.paragraphs):
                if para.text.strip():
                    full_text.append(para.text)
                else:
                    logging.debug(f"–ü—É—Å—Ç–æ–π –ø–∞—Ä–∞–≥—Ä–∞—Ñ –≤ DOCX '{file_path}', –Ω–æ–º–µ—Ä {i}")
            return "\n".join(full_text)
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {file_path}: {e}", exc_info=True)
        return None

async def save_resume(file: types.Document, user_id: int) -> Optional[int]:
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—é–º–µ –≤ –ë–î."""
    try:
        if file.file_size > MAX_FILE_SIZE:
            logging.warning(f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π: {file.file_size} –±–∞–π—Ç")
            return None

        file_buffer = io.BytesIO()
        await bot.download(file, destination=file_buffer)
        file_bytes = file_buffer.getvalue()

        temp_path = Path(f"temp_{user_id}_{file.file_name}")
        try:
            with open(temp_path, 'wb') as f:
                f.write(file_bytes)

            text = await parse_resume(str(temp_path))
            if not text:
                logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞: {file.file_name}")
                return None

            content_hash = hashlib.md5(text.encode('utf-8')).hexdigest()

            file_path = f"resumes/{user_id}/{content_hash}_{file.file_name}"
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            with open(file_path, 'wb') as f:
                f.write(file_bytes)

            conn = await get_db_conn()
            try:
                existing_resume = await conn.fetchval(
                    "SELECT resume_id FROM resumes WHERE file_hash = $1",
                    content_hash
                )
                if existing_resume:
                    logging.info(f"–†–µ–∑—é–º–µ —Å hash {content_hash} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π ID: {existing_resume}")
                    return existing_resume

                resume_id = await conn.fetchval(
                    """
                    INSERT INTO resumes (file_path, file_hash, original_name, file_size, uploaded_by_id)
                    VALUES ($1, $2, $3, $4, $5)
                    RETURNING resume_id
                    """,
                    file_path, content_hash, file.file_name, file.file_size, user_id
                )
                logging.info(f"–†–µ–∑—é–º–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ —Å ID: {resume_id}")
                return resume_id
            finally:
                await conn.close()

        finally:
            if temp_path.exists():
                temp_path.unlink()

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—é–º–µ: {str(e)}", exc_info=True)
        return None

# –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å DeepSeek
async def analyze_with_deepseek(vacancy_text: str, resumes: List[Dict]) -> List[Dict]:
    """–ó–∞–ø—Ä–æ—Å –∫ DeepSeek API –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ä–µ–∑—é–º–µ."""
    try:
        logging.info(f"–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ DeepSeek –¥–ª—è –≤–∞–∫–∞–Ω—Å–∏–∏ –¥–ª–∏–Ω–æ–π {len(vacancy_text)} —Å–∏–º–≤–æ–ª–æ–≤ –∏ {len(resumes)} —Ä–µ–∑—é–º–µ")
        resumes_text = "\n\n---\n\n".join(
            f"ID: {r['resume_id']}\n–¢–µ–∫—Å—Ç: {r['text'][:500]}..." for r in resumes  # –æ–±—Ä–µ–∑–∞–µ–º –¥–ª—è –ª–æ–≥–æ–≤
        )

        messages = [
            {
                "role": "system",
                "content": (
                    "–¢—ã HR-—ç–∫—Å–ø–µ—Ä—Ç. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä–µ–∑—é–º–µ –ø—Ä–æ—Ç–∏–≤ –≤–∞–∫–∞–Ω—Å–∏–∏. "
                    "–í–µ—Ä–Ω–∏ —Å–ø–∏—Å–æ–∫ JSON –æ–±—ä–µ–∫—Ç–æ–≤ —Å –ø–æ–ª—è–º–∏: resume_id (—á–∏—Å–ª–æ), full_name (—Å—Ç—Ä–æ–∫–∞), "
                    "score (—Ü–µ–ª–æ–µ –æ—Ç 0 –¥–æ 100), details (—Å—Ç—Ä–æ–∫–∞). –ë–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π."
                )
            },
            {
                "role": "user",
                "content": f"–í–∞–∫–∞–Ω—Å–∏—è: {vacancy_text}\n\n–†–µ–∑—é–º–µ:\n{resumes_text}"
            }
        ]

        async with httpx.AsyncClient(timeout=30.0) as client:
            logging.info("–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ DeepSeek API...")
            response = await client.post(
                DEEPSEEK_URL,
                json={
                    "model": "deepseek-chat",
                    "messages": messages,
                    "temperature": 0.1
                },
                headers={
                    "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
                    "Content-Type": "application/json"
                }
            )
            logging.info(f"–ü–æ–ª—É—á–µ–Ω —Å—Ç–∞—Ç—É—Å –æ—Ç–≤–µ—Ç–∞ –æ—Ç DeepSeek: {response.status_code}")
            response.raise_for_status()
            result = response.json()

            logging.info(f"DeepSeek API –æ—Ç–≤–µ—Ç: {result}")

            if "choices" in result and result["choices"]:
                content = result["choices"][0]["message"]["content"]
                logging.info(f"–û—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏: {content[:500]}...")

                json_match = re.search(r'\[\s*\{.*\}\s*\]', content, re.DOTALL)
                if json_match:
                    try:
                        matches = json.loads(json_match.group())
                        logging.info(f"–£—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—à–µ–Ω JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞ DeepSeek: {len(matches)} matches")
                        return matches
                    except json.JSONDecodeError as je:
                        logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON: {je}")
                        logging.debug(f"–°–æ–¥–µ—Ä–∂–∏–º–æ–µ, –∫–æ—Ç–æ—Ä–æ–µ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å: {json_match.group()}")
                else:
                    logging.error("JSON –º–∞—Å—Å–∏–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ")
                    logging.debug(f"–í–µ—Å—å –æ—Ç–≤–µ—Ç: {content}")
            return []

    except Exception as e:
        logging.error(f"DeepSeek API –æ—à–∏–±–∫–∞: {e}", exc_info=True)
        return []

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–æ–º–∞–Ω–¥
@dp.message(Command("start"))
async def start(message: Message):
    await message.answer(
        "ü§ñ –ü—Ä–∏–≤–µ—Ç! –Ø HR-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –æ—Ç–±–æ—Ä–∞ —Ä–µ–∑—é–º–µ.\n"
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏ —Ç–µ–∫—Å—Ç–æ–º, –∞ –∑–∞—Ç–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ä–µ–∑—é–º–µ (PDF/DOCX)."
    )

@dp.message(Command("process"))
async def process_resumes(message: Message):
    """–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∑—é–º–µ."""
    try:
        user_id = message.from_user.id
        if user_id not in user_state or not user_state[user_id].get("resume_ids"):
            await message.answer("‚ö† –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏! –°–Ω–∞—á–∞–ª–∞ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –≤–∞–∫–∞–Ω—Å–∏—é –∏ —Ä–µ–∑—é–º–µ.")
            return

        logging.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} –∑–∞–ø—É—Å—Ç–∏–ª –æ–±—Ä–∞–±–æ—Ç–∫—É. –†–µ–∑—é–º–µ: {len(user_state[user_id]['resume_ids'])}")
        logging.info(f"–°–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ resume_ids: {user_state[user_id]['resume_ids']}")

        conn = await get_db_conn()
        try:
            logging.info(f"–ó–∞–ø—Ä–æ—Å –∫ –ë–î: –ø–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑—é–º–µ —Å ID {user_state[user_id]['resume_ids']}")
            resumes = await conn.fetch(
                """
                SELECT resume_id, file_path 
                FROM resumes 
                WHERE resume_id = ANY($1::int[])
                """,
                user_state[user_id]["resume_ids"]
            )
            logging.info(f"–ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—é–º–µ –≤ –ë–î: {len(resumes)}")

            for r in resumes:
                logging.debug(f"–†–µ–∑—é–º–µ ID: {r['resume_id']}, –ü—É—Ç—å: {r['file_path']}")

        finally:
            await conn.close()

        if not resumes:
            await message.answer("‚ùå –ù–µ—Ç —Ä–µ–∑—é–º–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –ë–î).")
            return

        parsed_resumes = []
        for resume in resumes:
            logging.info(f"–ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—é–º–µ ID {resume['resume_id']} –ø–æ –ø—É—Ç–∏: {resume['file_path']}")
            text = await parse_resume(resume['file_path'])
            if text:
                logging.info(f"–£—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á—ë–Ω —Ç–µ–∫—Å—Ç –∏–∑ —Ä–µ–∑—é–º–µ {resume['resume_id']} (–¥–ª–∏–Ω–∞: {len(text)})")
                parsed_resumes.append({
                    "resume_id": resume['resume_id'],
                    "text": text
                })
            else:
                logging.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ —Ä–µ–∑—é–º–µ {resume['resume_id']}")

        logging.info(f"–£—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—à–µ–Ω–æ —Ä–µ–∑—é–º–µ: {len(parsed_resumes)} –∏–∑ {len(resumes)}")

        if not parsed_resumes:
            await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ —Ä–µ–∑—é–º–µ.")
            return

        matches = await analyze_with_deepseek(
            user_state[user_id]['vacancy_text'],
            parsed_resumes
        )
        logging.info(f"DeepSeek –≤–µ—Ä–Ω—É–ª matches: {len(matches)}")

        if not matches:
            await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—é–º–µ.")
            return

        # –ü—Ä–∏–≤–µ–¥—ë–º —Ç–∏–ø—ã –∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ resume_id
        valid_matches = []
        for m in matches:
            try:
                m['resume_id'] = int(m['resume_id'])
                m['score'] = int(m['score'])
                if 0 <= m['score'] <= 100:
                    valid_matches.append(m)
                else:
                    logging.warning(f"–û—Ü–µ–Ω–∫–∞ –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ [0-100]: {m['score']}")
            except (ValueError, KeyError) as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –≤ match: {m}, –æ—à–∏–±–∫–∞: {e}")
                continue

        top_matches = sorted(valid_matches, key=lambda x: x['score'], reverse=True)[:5]
        logging.info(f"–¢–æ–ø-5 matches: {[(m['score'], m.get('full_name', 'No name')) for m in top_matches]}")

        conn = await get_db_conn()
        try:
            logging.info("–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –≤ –ë–î...")
            vacancy_id = await conn.fetchval(
                """
                INSERT INTO vacancies (hr_user_id, title, description) 
                VALUES ($1, $2, $3) 
                RETURNING vacancy_id
                """,
                user_id, "Auto-generated", user_state[user_id]['vacancy_text']
            )
            logging.info(f"–í–∞–∫–∞–Ω—Å–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ —Å ID: {vacancy_id}")

            for match in top_matches:
                logging.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ match: resume_id={match['resume_id']}, score={match['score']}")
                await conn.execute(
                    """
                    INSERT INTO matches (vacancy_id, resume_id, score, details)
                    VALUES ($1, $2, $3, $4)
                    """,
                    vacancy_id, match['resume_id'], match['score'], match['details']
                )
            logging.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ matches –≤ –ë–î: {len(top_matches)}")

        finally:
            await conn.close()

        response = ["üèÜ –¢–æ–ø-5 –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤:"]
        for i, match in enumerate(top_matches, 1):
            name = match.get('full_name', '–ò–º—è –Ω–µ —É–∫–∞–∑–∞–Ω–æ')
            response.append(f"{i}. {name} - {match['score']}/100")

        await message.answer("\n".join(response))

        del user_state[user_id]
        logging.info(f"–°–µ—Å—Å–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id} –æ—á–∏—â–µ–Ω–∞")

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–µ–∑—é–º–µ: {e}", exc_info=True)
        await message.answer("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ.")

@dp.message(Command("status"))
async def show_status(message: Message):
    """–ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ"""
    user_id = message.from_user.id
    if user_id in user_state:
        vacancy_len = len(user_state[user_id]["vacancy_text"])
        resume_count = len(user_state[user_id]["resume_ids"])
        await message.answer(
            f"üìä –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ:\n"
            f"–í–∞–∫–∞–Ω—Å–∏—è: {vacancy_len} —Å–∏–º–≤–æ–ª–æ–≤\n"
            f"–†–µ–∑—é–º–µ: {resume_count} —Ñ–∞–π–ª–æ–≤\n"
            f"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /process –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"
        )
    else:
        await message.answer("‚Ñπ –ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–π —Å–µ—Å—Å–∏–∏. –û—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏ —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å.")

@dp.message(Command("status"))
async def show_status(message: Message):
    """–ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ"""
    user_id = message.from_user.id
    if user_id in user_state:
        vacancy_len = len(user_state[user_id]["vacancy_text"])
        resume_count = len(user_state[user_id]["resume_ids"])
        await message.answer(
            f"üìä –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ:\n"
            f"–í–∞–∫–∞–Ω—Å–∏—è: {vacancy_len} —Å–∏–º–≤–æ–ª–æ–≤\n"
            f"–†–µ–∑—é–º–µ: {resume_count} —Ñ–∞–π–ª–æ–≤\n"
            f"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /process –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"
        )
    else:
        await message.answer("‚Ñπ –ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–π —Å–µ—Å—Å–∏–∏. –û—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏ —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å.")

@dp.message(Command("help"))
async def help_command(message: Message):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Å–ø—Ä–∞–≤–∫—É –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –±–æ—Ç–∞."""
    help_text = (
        "üìö <b>–°–ø—Ä–∞–≤–∫–∞ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é HR-–±–æ—Ç–∞</b>\n\n"
        "–Ø –ø–æ–º–æ–≥—É –≤–∞–º –æ—Ç–æ–±—Ä–∞—Ç—å –ª—É—á—à–∏–µ —Ä–µ–∑—é–º–µ –ø–æ–¥ –≤–∞—à—É –≤–∞–∫–∞–Ω—Å–∏—é.\n\n"
        "<b>–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:</b>\n\n"
        "üî∏ <code>/start</code> ‚Äî –Ω–∞—á–∞—Ç—å —Ä–∞–±–æ—Ç—É —Å –±–æ—Ç–æ–º\n"
        "üî∏ <code>/help</code> ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ\n"
        "üî∏ <code>/status</code> ‚Äî –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ (–≤–∞–∫–∞–Ω—Å–∏—è –∏ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ä–µ–∑—é–º–µ)\n"
        "üî∏ <code>/process</code> ‚Äî –∑–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—é–º–µ –∏ –ø–æ–ª—É—á–∏—Ç—å —Ç–æ–ø-–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤\n\n"
        "<b>–ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç:</b>\n"
        "1. –û—Ç–ø—Ä–∞–≤—å—Ç–µ <b>–æ–ø–∏—Å–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏</b> —Ç–µ–∫—Å—Ç–æ–º\n"
        "2. –ó–∞–≥—Ä—É–∑–∏—Ç–µ <b>—Ä–µ–∑—é–º–µ</b> –≤ —Ñ–æ—Ä–º–∞—Ç–µ PDF –∏–ª–∏ DOCX (–¥–æ 50 —Ñ–∞–π–ª–æ–≤)\n"
        "3. –ù–∞–∂–º–∏—Ç–µ <code>/process</code>, —á—Ç–æ–±—ã –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤\n\n"
        "–Ø –∏—Å–ø–æ–ª—å–∑—É—é –ò–ò –¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Ä–µ–∑—é–º–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –∏ –≤–µ—Ä–Ω—É –≤–∞–º —Ç–æ–ø-5 –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ —Å –æ—Ü–µ–Ω–∫–æ–π –æ—Ç 0 –¥–æ 100.\n\n"
        "üí° –ï—Å–ª–∏ —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ <code>/start</code>, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –∑–∞–Ω–æ–≤–æ."
    )
    await message.answer(help_text, parse_mode=ParseMode.HTML)
# –û—Å–Ω–æ–≤–Ω–æ–π workflow
@dp.message(F.text)
async def handle_vacancy_description(message: Message):
    """–®–∞–≥ 1: –ü–æ–ª—É—á–µ–Ω–∏–µ –æ–ø–∏—Å–∞–Ω–∏—è –≤–∞–∫–∞–Ω—Å–∏–∏."""
    try:
        user_id = message.from_user.id
        if user_id in user_state:
            if user_state[user_id]["resume_ids"]:
                await message.answer(
                    "‚ö† –í—ã —É–∂–µ –∑–∞–≥—Ä—É–∑–∏–ª–∏ —Ä–µ–∑—é–º–µ. –ß—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –∑–∞–Ω–æ–≤–æ, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /start."
                )
                return
        if len(message.text) > 5000:
            await message.answer("‚ùå –û–ø–∏—Å–∞–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ (–º–∞–∫—Å. 5000 —Å–∏–º–≤–æ–ª–æ–≤).")
            return

        user_state[user_id] = {
            "vacancy_text": message.text,
            "resume_ids": []
        }

        logging.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} —Å–æ—Ö—Ä–∞–Ω–∏–ª –≤–∞–∫–∞–Ω—Å–∏—é. –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {len(message.text)}")

        await message.answer(
            "‚úÖ –û–ø–∏—Å–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ. –¢–µ–ø–µ—Ä—å –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ä–µ–∑—é–º–µ (PDF/DOCX).\n"
            f"–õ–∏–º–∏—Ç: {MAX_RESUMES} —Ñ–∞–π–ª–æ–≤, –∫–∞–∂–¥—ã–π –¥–æ {MAX_FILE_SIZE // 1024 // 1024} MB."
        )
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∞–∫–∞–Ω—Å–∏–∏: {e}", exc_info=True)
        await message.answer("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞–∫–∞–Ω—Å–∏–∏.")

@dp.message(F.document)
async def handle_resumes(message: Message):
    """–®–∞–≥ 2: –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ä–µ–∑—é–º–µ."""
    try:
        user_id = message.from_user.id
        if user_id not in user_state:
            await message.answer("‚ö† –°–Ω–∞—á–∞–ª–∞ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏!")
            return
        file = message.document
        if not file.file_name.lower().endswith(('.pdf', '.docx')):
            await message.answer("‚ùå –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ PDF/DOCX.")
            return

        logging.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} –∑–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∞–π–ª: {file.file_name}")

        resume_id = await save_resume(file, user_id)
        if not resume_id:
            await message.answer("‚ùå –§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –∏–ª–∏ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω.")
            return

        user_state[user_id]["resume_ids"].append(resume_id)
        count = len(user_state[user_id]["resume_ids"])

        logging.info(f"–†–µ–∑—é–º–µ –¥–æ–±–∞–≤–ª–µ–Ω–æ –∫ —Å–µ—Å—Å–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}. –í—Å–µ–≥–æ —Ä–µ–∑—é–º–µ: {count}")

        await message.answer(
            f"‚úÖ –†–µ–∑—é–º–µ '{file.file_name}' –∑–∞–≥—Ä—É–∂–µ–Ω–æ. "
            f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ä–µ–∑—é–º–µ: {count}. –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –µ—â–µ –∏–ª–∏ –Ω–∞–∂–∞—Ç—å /process."
        )
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–µ–∑—é–º–µ: {e}")
        await message.answer("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ä–µ–∑—é–º–µ.")

async def main():
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    )
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())